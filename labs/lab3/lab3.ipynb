{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab3.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dsci511_header.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Introduction to NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "rubric={mechanics:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from random import gauss\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.rcParams.update({'font.size': 14, 'axes.labelweight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: NumPy warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following array and save it as a variable `ex1_1`:\n",
    "\n",
    "```python\n",
    "array([[1, 2],\n",
    "       [3, 4],\n",
    "       [5, 6]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex1_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the following `arr` into shape `(6, 1)` and save the result as `ex1_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "ex1_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `(6, 6)` array by multiplying the following `arr` by itself (**hint**: leverage broadcasting here). The first element (top left corner) should be 1, and the last element (bottom right corner) should be 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.arange(1, 7)[np.newaxis, :]\n",
    "ex1_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Center\" the following `arr` by subtracting the mean from every element, then flatten it to shape `(20,)` and sort it in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.arange(1, 21).reshape(4, 5)\n",
    "ex1_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Vectorizing loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "rubric={accuracy:2,quality:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following mathematical function simulates a stock price using geometric Brownian motion. In this model, price in the next timestep $S_{t+1}$ depends on the current price $S_{t}$ as follows:\n",
    "\n",
    "$$S_{t+1} = S_{t} \\exp \\left( -0.5\\sigma^2 + \\sigma Z \\right)$$\n",
    "\n",
    "where $Z$ is a random number drawn from a standard [Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution), and $\\sigma$ is the _volatility_ of the stock (i.e., if $\\sigma=0$ then the stock price never changes, whereas if $\\sigma$ is large the stock price can change wildly).\n",
    "\n",
    "Here, we have the Python function `simulate(S0, sigma, T)` that computes simulated stock prices according to the above given formula, and stores price values at each timestep as elements inside a Python list. This list is eventually returned by the function as the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(S0=1.0, sigma=0.1, T=1000):\n",
    "    \"\"\"\n",
    "    Simulates a stock price using geometric Brownian motion, \n",
    "    and returns a list containing the results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S0 : float \n",
    "        the initial stock price\n",
    "    sigma : float \n",
    "        the volatility, should be non-negative\n",
    "    T : int\n",
    "        the total number of time steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The list containing stock prices at each time step \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> simulate(3.9, 0.5, 4)\n",
    "    [3.9, 3.16886711, 1.06006414, 0.79470699]\n",
    "    \"\"\"\n",
    "    \n",
    "    S = [S0]\n",
    "    # append to list for each time step\n",
    "    for t in range(1, T):\n",
    "        Z = gauss(0, 1)\n",
    "        S.append(S[-1] * math.exp(-0.5 * sigma ** 2 + sigma * Z))\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task here is to re-write this function as a new function called `simulate_np(S0, sigma, T)` using NumPy such that **you don't explicitly use for loops**.\n",
    "\n",
    "Let's do some math first to simplify things a bit. Let's denote $\\theta = \\exp \\left( -0.5\\sigma^2 + \\sigma Z \\right)$, then:\n",
    "\n",
    "$$S_{1} = S_{0} \\theta_0$$\n",
    "\n",
    "$$S_{2} = S_{1} \\theta_{1} = S_{0} \\theta_0 \\theta_{1}$$\n",
    "\n",
    "$$S_{3} = S_{2} \\theta_{2} = S_{0} \\theta_0 \\theta_{1} \\theta_{2}$$\n",
    "\n",
    "$$\\dots$$\n",
    "\n",
    "$$S_{T} = S_{0} \\prod_{t=0}^{T-1} \\theta_{t}$$\n",
    "\n",
    "- $\\theta$ does not depend on the stock price at time `t`, so you can create $\\prod_{t=0}^{T-1} \\theta_{t}$ without using a loop.\n",
    "\n",
    "- You can create an array of `Z`s with `np.random.randn()`.\n",
    "\n",
    "- You can calculate the cumulative product of an array using the `cumprod()` method.\n",
    "\n",
    "- Your function should return an `ndarray` object instead of a `list`.\n",
    "\n",
    "- Don't forget to adapt the docstring of `simulate()` to your new function `simulate_np()`.\n",
    "\n",
    "- You are given some plotting code to test out your function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_np():\n",
    "    ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you can use for plotting your function\n",
    "price = simulate_np(S0=1, sigma=0.1, T=1000)\n",
    "plt.plot(price)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2.2\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this question is to help drive home the power of vectorized array operations in NumPy vs iteration in base Python.\n",
    "\n",
    "Write code to record how long it takes for `simulate()` and your new-and-improved `simulate_np()` to run 10,000 times (using their default values of `S0=1, sigma=0.1, T=1000`).\n",
    "\n",
    "You can use the `time` module to help calculate the time it takes (in [real time](https://communities.sas.com/t5/SAS-Programming/Real-Time-vs-CPU-time/td-p/287743#:~:text=Real%20Time%20is%20the%20actual,the%20step%20utilises%20CPU%20resources.)) for your code to execute.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- The `time` module has already been imported for you at the start of the lab.\n",
    "\n",
    "- `time.time()` gives you the current clock time (so you can save a variable `start = time.time()` before you code and `end = time.time()` after your code and compare the difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Exercise 3: NumPy wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a 400 x 400 pixel image of the UBC logo, imported and displayed with `matplotlib` (one of the most popular Python plotting packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread('img/ubc.jpeg')[:, :, 0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Max. pixel value: {image.max()}\")\n",
    "print(f\"Min. pixel value: {image.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `cmap=gray` parameter in `plt.imshow()` is to force `matplotlib` to interpret the array as grayscale values (instead of showing an irrelevant colormap by default).\n",
    "\n",
    "As you can see, `image` is just a NumPy array of size `(400, 400)`, with values ranging from 0 to 255.\n",
    "\n",
    "Your task is to write a code that **flips the image about both the horizontal and vertical axes**, so that it looks as if we rotated the image 180 degrees clockwise:\n",
    "\n",
    "![](img/ubc_flipped.jpeg)\n",
    "\n",
    "- Do not overwrite the `image` variable, we will use it in the next few questions.\n",
    "\n",
    "- NumPy has helpful functions for \"flipping\" arrays. You can try typing `np.flip` to see what the auto-complete reveals.\n",
    "\n",
    "- **Don't forget to show your resulting image in the output using `plt.imshow()`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 3.2\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you want to prepare this image to post on Instagram, and you think a 20-pixels-wide black border will really make it stand out. Add a 20-pixels-wide black border to the image so that it looks like this:\n",
    "\n",
    "![](img/ubc_border.jpeg)\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- The image including the border should remain 400 x 400 pixels (i.e., you are adding the border within the image), **do not** add it to the outside and make the image 440 x 440 pixels.\n",
    "\n",
    "- Black pixels have a value of `0` (i.e., they have 0 brightness).\n",
    "\n",
    "- There are many ways to solve this question so do it however you like, but `np.pad()` might be super helpful to make your solution shorter.\n",
    "\n",
    "- **Don't forget to show your resulting image in the output using `plt.imshow()`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 3.3 (OPTIONAL)\n",
    "rubric={accuracy:1% of total grade}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DSCI 572 you'll learn about [Convolutional Neural Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN), which are often used when working with image data. A common operation in a CNN architecture is [pooling](https://cs231n.github.io/convolutional-networks/#pool), in which you reduce the size of an image by looking at a small window of pixels, say a 4 x 4 window of pixels, and representing that window using e.g., the max/min/mean value of the pixels in the window.\n",
    "\n",
    "Below is an example of mean pooling, transforming a 6 x 6 image into a 3 x 3 image by taking the mean of 2 x 2 pixel windows:\n",
    "\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f\" width=\"400\">\n",
    "\n",
    "Source: [stanford.edu](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)\n",
    "\n",
    "Let's implement pooling in NumPy here to get a feel of how it works. We can do it by reshaping our image into `n x n` windows and then calculating the `.max()` of each window. Your task here is to implement **mean** pooling on the UBC logo image using a `10 x 10` window, resulting in an image that will look like this:\n",
    "\n",
    "![](img/ubc_mean_pool.jpeg)\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- There are plenty of ways you could solve this question. One way is to start by reshaping each axis of the image into shape `(40, 10)` to end up with a 4D array of shape `(40, 10, 40, 10)`.\n",
    "\n",
    "- Then apply `.mean()` to the reshaped data on both axes of size 10. You can specify multiple axes to operate on simultaneously by passing a tuple to the `axis=` parameter of the `mean()` method.\n",
    "\n",
    "- Play around with you code to get a feel for what pooling does. What happens if you increase/decrease the pooling window size? Also feel free to try using `min()` or `max()` methods, for example: \n",
    "\n",
    "![](img/ubc_min_pool.jpeg)\n",
    "\n",
    "- See [here](https://stackoverflow.com/a/42463514) for more help.\n",
    "\n",
    "- **Don't forget to show your resulting image in the output using `plt.imshow()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Exercise 4: Reading data with Pandas \n",
    "\n",
    "rubric={autograde:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from external sources will be one of the most common things you do in Pandas, so it's good to get some practice doing this. We will use Pandas to read in variants of the Palmer penguins dataset that you've already seen in DSCI 523. In this data set, there are measures on the three species of penguins shown in this illustration below. You can learn more about the penguins and this dataset [here](https://allisonhorst.github.io/palmerpenguins/).\n",
    "\n",
    "<img src=\"img/penguins.png\" width=\"500\">\n",
    "\n",
    "Source: [allisonhorst.github.io](https://github.com/allisonhorst/palmerpenguins/blob/master/man/figures/lter_penguins.png?raw=true)\n",
    "\n",
    "- In the `data` directory of this repository, there are 5 different versions of the same dataset in different file formats. Your task is to read each of these into a Pandas dataframe, **such that all dataframes look exactly like the one created by reading `penguins.csv`**.\n",
    "\n",
    "- **Hint:** Some dataframes have redundant lines in the beginning of the file, some are separated by characters other than comma, some have extra columns, some don't have the right column names, etc. You should take these into account and read in the data such that they all look alike.\n",
    "\n",
    "- **Hint:** If you want, you can compare which rows of two dataframes are not equal using something like `penguins_csv[~penguins_csv.eq(penguins_tsv).any(axis=1)]`.\n",
    "\n",
    "- Tests are provided to make sure you've correctly read each file in. The tests use `df1.equals(df2)` to check for differences between a dataframe `df1` and another one `df2`.\n",
    "\n",
    "**Note:** If python complains about the package `openpyxl` not being available on your system, you can run the following command in a terminal to install it:\n",
    "\n",
    "```shell\n",
    "conda install -y openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in file named penguins.csv\n",
    "penguins_csv = ...\n",
    "# read in file named penguins.tsv\n",
    "penguins_tsv = ...\n",
    "# read in file named penguins-meta-data.csv\n",
    "penguins_meta_data = ...\n",
    "# read in file named penguins2.csv\n",
    "penguins2 = ...\n",
    "# read in file named penguins.xlsx\n",
    "penguins_excel = ...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Treasure hunt with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning how to index with Pandas is kind of like having to eat your vegetables: it's not the funnest thing, but you need to know it! In this exercise, I'll provide you with clues that you need to use to index a dataframe and find the \"Treasure\". For example, if the clue is \"The first ten rows\" then you might try:\n",
    "\n",
    "```python\n",
    ">>> df.iloc[:10]\n",
    "```\n",
    "\n",
    "The above is just an example, but the result of your indexing should always be the string `'TREASURE'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the file `treasure_hunt.csv` as a dataframe called `treasure_df`. Read in the first column as the dataframe index column and the first row as the dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treasure_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** C20, R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_2 = ...\n",
    "ex5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** thirteenth column, thirteenth row (**hint:** recall that indexing starts at 0!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_3 = ...\n",
    "ex5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** R28, tenth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_4 = ...\n",
    "ex5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** C26, R19 to R26\n",
    "\n",
    "**Hint:** You might need to do a bit of extra wrangling (e.g. joining stuff, maybe?) to get a result of \"TREASURE\" here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_5 = ...\n",
    "ex5_5\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** The first rows of C29 *plus* the first row of C30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_6 = ...\n",
    "ex5_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** The first row of all columns that **do not** have a \"Z\" in the last row.\n",
    "\n",
    "**Hint:** You might need to do a bit of extra wrangling to get a result of \"TREASURE\" here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_7 = ...\n",
    "ex5_7\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8\n",
    "rubric={autograde:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clue:** C1 for C1 < C2 (remember, in Python, comparison operators work on string too, e.g., `\"a\" < \"b\" = True` because `a` occurs before `b` alphabetically. Also, don't forget about `.query()`!)\n",
    "\n",
    "**Hint:** You might need to do a bit of extra wrangling to get a result of \"TREASURE\" here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex5_8 = ...\n",
    "ex5_8\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Mind the gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll practice some basic Pandas operations on the [Gapminder dataset](https://www.gapminder.org/about/) which you are already familiar with from your DSCI 523 labs. Gapminder is an educational foundation that aims to use data to unbiasedly describe trends in health and socioeconomics; it is a great source of geographical, socioeconomic, and health data - a subset of which we'll be exploring here. In particular, we'll be exploring a dataframe of the following features in this exercise:\n",
    "\n",
    "|     | country     | continent | year | lifeExp | pop      | gdpPercap  |\n",
    "|:---:|:-----------:|:---------:|:----:|:-------:|:--------:|:----------:|\n",
    "|  0  | Afghanistan | Asia      | 1952 | 28.801  | 8425333  | 779.445314 |\n",
    "|  1  | Afghanistan | Asia      | 1957 | 30.332  | 9240934  | 820.853030 |\n",
    "|  2  | Afghanistan | Asia      | 1962 | 31.997  | 10267083 | 853.100710 |\n",
    "|  3  | Afghanistan | Asia      | 1967 | 34.020  | 11537966 | 836.197138 |\n",
    "|  4  | Afghanistan | Asia      | 1972 | 36.088  | 13079460 | 739.981106 |\n",
    "| ... |     ...     |    ...    | ...  |   ...   |   ...    |    ...     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the gapminder dataset into a dataframe called `df` from this url: <https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 6.2\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which continent has the most observations in the gapminder dataset? You can leave your answer as the output of a dataframe operation (**hint:** `.value_counts()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 6.3\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the minimum and maximum life expectancies in the dataset, and what are the corresponding countries and the years? (**hint:** `.argmin()`/`.argmax()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 6.4\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much larger is the total population in this dataset in 2007 compared to 1952? You can give you answer as a float, e.g., \"the population is 1.8 times larger in 2007 than in 1952.\" (**hint:** you can use `.query()` to subset the dataframe for 1952 and then calculate the `.sum()` of the population, then repeat for 2007)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 6.5\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the mean life expectancy of countries with the highest 50% of `gdpPercap` and countries with the lowest 50% of `gdpPercap`? (**hint:** try combining `.query()` and `.median()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high = ...\n",
    "low = ...\n",
    "print(f\"Life expectancy of wealthy countries: {high:.0f} years\")\n",
    "print(f\" Life expectancy of poorer countries: {low:.0f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dsci511')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert type(ex1_1) == np.ndarray\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_1.shape == (3, 2)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_1[0][0] == 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_1[0][1] == 2\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_1[2][0] == 5\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_1[2][1] == 6\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2": {
     "name": "q1_2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert type(ex1_2) == np.ndarray\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_2.shape == (6, 1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_2[0] == 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_2[-1] == 6\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_3": {
     "name": "q1_3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert type(ex1_3) == np.ndarray\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_3.shape == (6, 6)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_3[0, 0] == 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_3[-1, -1] == 36\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_4": {
     "name": "q1_4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert type(ex1_4) == np.ndarray\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_4.shape == (20,)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_4[0] == 9.5\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_4[-1] == -9.5\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ex1_4.sum() == 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert pd.read_csv(\"data/penguins.csv\").equals(penguins_tsv)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert pd.read_csv(\"data/penguins.csv\").equals(penguins_meta_data)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert pd.read_csv(\"data/penguins.csv\").equals(penguins2)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert pd.read_csv(\"data/penguins.csv\").equals(penguins_excel)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_1": {
     "name": "q5_1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert type(treasure_df) == pd.DataFrame\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ''.join(treasure_df.columns.values) == 'C1C2C3C4C5C6C7C8C9C10C11C12C13C14C15C16C17C18C19C20C21C22C23C24C25C26C27C28C29C30'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> assert ''.join(treasure_df.index.values) == 'R1R2R3R4R5R6R7R8R9R10R11R12R13R14R15R16R17R18R19R20R21R22R23R24R25R26R27R28R29R30'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_2": {
     "name": "q5_2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_2 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_3": {
     "name": "q5_3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_3 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_4": {
     "name": "q5_4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_4 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_5": {
     "name": "q5_5",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_5 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_6": {
     "name": "q5_6",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_6 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_7": {
     "name": "q5_7",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_7 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_8": {
     "name": "q5_8",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> assert ex5_8 == 'TREASURE'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "e48f8b1687318edbd5a2a918b592db3baee1b5f69ffdc30179f0c7d8337e101b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
